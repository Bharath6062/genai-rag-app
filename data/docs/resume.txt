Bharath Reddy
bharath@myjobemails.com | Minnesota, USA | +1 (763) 210-8511 | LinkedIn
PROFESSIONAL SUMMARY
Data Engineer with 3+ years of experience, have a proven track record in designing, implementing, and maintaining robust 
data infrastructure and pipelines. Proficient in Python, SQL, and Scala and Machine Learning, Specialize in ETL processes, 
leveraging tools like Apache Spark and Hadoop for distributed data processing and also proficient in NLP, Deep Learning, and 
machine learning models for analysis.
TECHNICAL SKILLS
 Programming & Libraries: Python, R, DAX, SQL, PL-SQL,NumPy, Pandas, Matplotlib, PySpark, Core Java, JavaScript
 Databases: MySQL, MS SQL Server, PostgreSQL, Snowflake, Oracle
 Tools: Tableau, Power BI, SSRS, PowerApps, Tableau Prep, Google Data Flow, Hadoop, HDFS, Spark, Hive, Pig, MapReduce, 
EMR, Kafka, Sqoop
 Data Science & Analytics: Machine Learning, Data Warehousing, Data Mining, Data bricks, Data Analytics, Data Modeling, 
Data Engineering, Database Querying, Microsoft Office 365, Power Query, DAX Functions, ETL Processing, Data Pipelines, 
Data Transformation, Ad-Hoc Analytics, Git Repository, JIRA, Data Verse, Data Visualization Docker, Jenkins, REST API's
PROFESSIONAL EXPERIENCE
Data Engineer, LTIMintree Aug 2023 – Present | Remote, USA
 Developed a real-time ETL pipeline with Apache Kafka and Spark (Scala) to analyze customer behavior data on an e commerce platform, resulting in a 15% increase in sales conversions.
 Utilized Hadoop and MapReduce to optimize large-scale historical data processing, implementing data mapping and 
transformation logic to ensure consistency and integrity across diverse sources.
 Architected and optimized the Snowflake data warehouse for efficient storage and retrieval of structured and unstructured 
data, ensuring scalability and performance for large datasets.
 Automated comprehensive ETL workflows using Python and SQL for data extraction, transformation, and loading into the 
warehouse, while leveraging MS Excel for ad-hoc analysis and reporting.
 Developed interactive dashboards using Power BI, enabling real-time visualization of key business metrics and empowering 
data-driven decision-making across departments.
 Integrated predictive models using Azure Machine Learning Services for customer churn prediction and personalized 
product recommendations, deploying models and data pipelines in the cloud with Azure Data Factory, Azure Blob Storage, 
and Azure Synapse Analytics for secure, scalable infrastructure.
 Automated CI/CD pipelines using Azure DevOps for efficient data infrastructure deployment, while optimizing Spark job 
performance and implementing monitoring tools for continuous improvement.
 Achieved a 10% reduction in customer churn and a 15% increase in sales conversions by leveraging real-time insights and 
predictive analytics, while automating end-to-end data workflows to enhance operational efficiency.
Data Engineer, HSBC Bank Mar 2021 – Dec 2022 | Hyderabad, India
 Developed a highly scalable data integration and real-time analytics platform using Python and PySpark, streamlining data 
processing and improving the organization’s ability to derive actionable insights for better decision-making.
 Architected and optimized ETL pipelines with Python, leveraging PySpark on Azure Databricks to enhance data processing 
by 40% and ensure high data quality across 10TB+ of structured, semi-structured, and unstructured data.
 Utilized Pandas, NumPy, and SQLAlchemy for efficient data manipulation and transformation within the pipelines, 
improving data management workflows.
 Implemented data validation and integrity checks and enforced data security, privacy, and PII handling using RBAC, least privilege access, and audit logging across Azure-based pipelines.
 Designed SQL Server schemas using indexes, constraints, and keys (primary/foreign) to improve query performance and reliability.
 Integrated machine learning models with scikit-learn and TensorFlow into data pipelines, automating forecasting and 
customer behavior prediction, achieving a 30% increase in accuracy and saving over 100 man-hours per month.
 Implemented CI/CD pipelines with Azure DevOps for continuous integration and deployment, reducing deployment time by 
50% and doubling the frequency of deployments to meet evolving business demands.
 Managed Azure-based data warehouse infrastructure utilizing Azure Blob Storage, Azure Synapse Analytics, Azure Data 
Factory, and Azure Data Lake, ensuring uptime and enabling real-time data access for 50+ global stakeholders.
 Leveraged Tableau for building interactive dashboards and visualizing key performance indicators, allowing real-time data 
analysis and better insights for stakeholders.
 Conducted data management tasks, including data cleansing, validation, and enrichment, using Python and SQL to ensure 
accurate and up-to-date data for business analysis and reporting.
EDUCATION
Master of Science, Concordia University st Paul Jan 2022 - May 2024 | Minnesota, USA
Information Technology and Management
Bachelor of Technology, NRI Institute and Technology June 2018 – May 2022 | Vijayawada, India
Electronics and Communication Engineering